{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course: _Convolutional Neural Networks for Image Processing_:\n",
    "1.  images\n",
    "2.  cnn part 1\n",
    "3.  cnn part 2\n",
    "4.  theory / optimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _1. Image Processing With Neural Networks_:\n",
    "-  shape => **(# samples, height, width, channels)**\n",
    "-  BGR => Blue, Green, Red\n",
    "-  greyscale => Black & White\n",
    "-  input_shape => **(height * width, )**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### view image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = plt.imread('./titan.jpg')\n",
    "\n",
    "plt.imshow(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# red\\ndata[:10, :10, 0] = 1\\n\\n# green\\ndata[:10, :10, 1] = 0\\n\\n# blue\\ndata[:10, :10, 2] = 0\\n\\nplt.imshow(data)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# red\n",
    "data[:10, :10, 0] = 1\n",
    "\n",
    "# green\n",
    "data[:10, :10, 1] = 0\n",
    "\n",
    "# blue\n",
    "data[:10, :10, 2] = 0\n",
    "\n",
    "plt.imshow(data)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ohe class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_categories = 3 # classes\n",
    "labels = ['shoe', 'shirt', 'shoe', 'shirt', 'dress', 'dress', 'dress'] # labels\n",
    "\n",
    "categories = np.array([\"shirt\", \"dress\", \"shoe\"])\n",
    "\n",
    "ohe_labels = np.zeros((len(labels), n_categories))\n",
    "\n",
    "for ii in range(len(labels)):\n",
    "    jj = np.where(categories == labels[ii])\n",
    "    ohe_labels[ii, jj] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "test_labels = np.array([[0., 0., 1.],\n",
    "       [0., 1., 0.],\n",
    "       [0., 0., 1.],\n",
    "       [0., 1., 0.],\n",
    "       [0., 0., 1.],\n",
    "       [0., 0., 1.],\n",
    "       [0., 0., 1.],\n",
    "       [0., 1., 0.]])\n",
    "\n",
    "predictions = np.array([[0., 0., 1.],\n",
    "       [0., 1., 0.],\n",
    "       [0., 0., 1.],\n",
    "       [1., 0., 0.],\n",
    "       [0., 0., 1.],\n",
    "       [1., 0., 0.],\n",
    "       [0., 0., 1.],\n",
    "       [0., 1., 0.]])\n",
    "\n",
    "number_correct = (test_labels * predictions).sum() # num of correct preds\n",
    "print(number_correct)\n",
    "\n",
    "proportion_correct = number_correct/len(predictions) # correct preds proportion\n",
    "print(proportion_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10, activation='relu', input_shape=(784,))) # 1st layer\n",
    "model.add(Dense(10, activation='relu')) # 2nd layer\n",
    "model.add(Dense(3, activation='softmax')) # output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_data = train_data.reshape(50, 784) # reshape data to 2D array\\nmodel.fit(train_data, train_labels, validation_split=0.2, epochs=3)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_data = train_data.reshape(50, 784) # reshape data to 2D array\n",
    "model.fit(train_data, train_labels, validation_split=0.2, epochs=3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_data = test_data.reshape(10, 784)\\nmodel.evaluate(test_data, test_labels) # evaluate on unseen data\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_data = test_data.reshape(10, 784)\n",
    "model.evaluate(test_data, test_labels) # evaluate on unseen data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _2. Using Convolutions_:\n",
    "- one dimensional convolutions:\n",
    "    1.  has a kernel\n",
    "    2.  slides kernel along the array\n",
    "    3.  multiplies kernel with items in array that overlap with the kernel in that location\n",
    "    4.  sum up the product\n",
    "-  filter:\n",
    "    -  feature maps (units)\n",
    "-  kernel:\n",
    "    -  shape of pixel input (ex: 3x3)\n",
    "-  stride:\n",
    "    -  length of sliding window along image\n",
    "    -  stride of 1 means every pixel is scanned; stride of 2 means every other pixel is skipped when sliding over image\n",
    "    -  larger strides means small output shape size\n",
    "-  padding:\n",
    "    -  used to ensure input shape of CNN has the same output shape of the CNN\n",
    "    -  allows convolutional layer to retain resolution of the input into this layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Output CNN Shape Size Formula:\n",
    "# O = ((I - K + 2P)/S) + 1\n",
    "- I => size of input\n",
    "- K => size of kernel\n",
    "- P => size of the zero padding\n",
    "- S => stride length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one dimensional convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 -1  1 -1  1 -1  0  0]\n"
     ]
    }
   ],
   "source": [
    "array = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
    "kernel = np.array([1, -1, 0]) # 3 elements\n",
    "conv = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "for ii in range(8): # multiply kernel w/ 8 different positions\n",
    "    conv[ii] = (kernel * array[ii:ii+3]).sum()\n",
    "\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkernel = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])\\nresult = np.zeros(im.shape)\\n\\n# Output array\\nfor ii in range(im.shape[0] - 3):\\n    for jj in range(im.shape[1] - 3):\\n        result[ii, jj] = (im[ii:ii+3, jj:jj+3] * kernel).sum()\\n\\n# Print result\\nprint(result)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "kernel = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])\n",
    "result = np.zeros(im.shape)\n",
    "\n",
    "# Output array\n",
    "for ii in range(im.shape[0] - 3):\n",
    "    for jj in range(im.shape[1] - 3):\n",
    "        result[ii, jj] = (im[ii:ii+3, jj:jj+3] * kernel).sum()\n",
    "\n",
    "# Print result\n",
    "print(result)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small image classification cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer; 10 = filter size aka feature maps; 3 = kernel shape 3x3\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
    "               input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Flatten the output of the convolutional layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add an output layer for the 3 categories\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train cnn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"model.compile(optimizer=\\'adam\\', \\n              loss=\\'categorical_crossentropy\\', \\n              metrics=[\\'accuracy\\'])\\n\\n# Fit the model on a training set\\nmodel.fit(train_data, train_labels, \\n          validation_split=0.2, \\n          epochs=3, batch_size=10)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model on a training set\n",
    "model.fit(train_data, train_labels, \n",
    "          validation_split=0.2, \n",
    "          epochs=3, batch_size=10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate model on holdout set (not from validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(test_data, test_labels, batch_size=10)\n",
    "\n",
    "# test_data.shape (10 images, 28x28 image size, grey scale channel)\n",
    "(10, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add the convolutional layer; \"same\" = padding makes input shape equal to output shape\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1), \n",
    "                 padding='same'))\n",
    "\n",
    "# Feed into output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(10, kernel_size=3, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1), \n",
    "                 strides=2))\n",
    "\n",
    "# Feed into output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output shape size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O = ((I - K + 2P)/S) + 1\n",
    "((256 - 4 + 2 * 1) / 2) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _3. Going Deeper_:\n",
    "-  Deep CNN => neural network with more than 1 layer; requires more data and computing power\n",
    "-  pooling:\n",
    "    -  reduces number of parameters\n",
    "    -  for every window in the input it finds the maximal pixel value and passes only this pixel through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deep cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer (15 units)\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "              \n",
    "# Add another convolutional layer (5 units)\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deep cnn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel.compile(optimizer='adam', \\n              loss='categorical_crossentropy', \\n              metrics=['accuracy'])\\n\\n# Fit the model to training data \\nmodel.fit(train_data, train_labels, \\n          validation_split=0.2, \\n          epochs=3, batch_size=10)\\n\\n# Evaluate the model on test data\\nmodel.evaluate(test_data, test_labels, batch_size=10)\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to training data \n",
    "model.fit(train_data, train_labels, \n",
    "          validation_split=0.2, \n",
    "          epochs=3, batch_size=10)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "model.evaluate(test_data, test_labels, batch_size=10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28x28 pixels\n",
    "# 1 convolutional layer; 10 units; 3x3 kernel\n",
    "# zero padding (input has same size as output)\n",
    "# 1 dense layer w/ 2 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15782"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3*3*10 + 10) + (28*28*10*2 + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 27, 27, 10)        50        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 10)        410       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 6760)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 20283     \n",
      "=================================================================\n",
      "Total params: 20,743\n",
      "Trainable params: 20,743\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(10, kernel_size=2, activation='relu', \n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(10, kernel_size=2, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Summarize the model \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### custom pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Result placeholder\\nresult = np.zeros((im.shape[0]//2, im.shape[1]//2))\\n\\n# Pooling operation\\nfor ii in range(result.shape[0]):\\n    for jj in range(result.shape[1]):\\n        result[ii, jj] = np.max(im[ii*2:ii*2+2, jj*2:jj*2+2])\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Result placeholder\n",
    "result = np.zeros((im.shape[0]//2, im.shape[1]//2))\n",
    "\n",
    "# Pooling operation\n",
    "for ii in range(result.shape[0]):\n",
    "    for jj in range(result.shape[1]):\n",
    "        result[ii, jj] = np.max(im[ii*2:ii*2+2, jj*2:jj*2+2])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keras pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 27, 27, 15)        75        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 15)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 12, 5)         305       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 2163      \n",
      "=================================================================\n",
      "Total params: 2,543\n",
      "Trainable params: 2,543\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a pooling operation\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel.compile(optimizer='adam', \\n              loss='categorical_crossentropy', \\n              metrics=['accuracy'])\\n\\n# Fit the model to training data \\nmodel.fit(train_data, train_labels, \\n          validation_split=0.2, \\n          epochs=3, batch_size=10)\\n\\n# Evaluate the model on test data\\nmodel.evaluate(test_data, test_labels, batch_size=10)\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to training data \n",
    "model.fit(train_data, train_labels, \n",
    "          validation_split=0.2, \n",
    "          epochs=3, batch_size=10)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "model.evaluate(test_data, test_labels, batch_size=10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _4. Understanding and Improving Deep Convolutional Networks_:\n",
    "- tracking learning:\n",
    "    - plot training loss vs validation loss\n",
    "    - visuals to see if model is overfitting\n",
    "-  how to prevent overfitting? - try **regularization** techniques\n",
    "    -  Dropout:\n",
    "        -  select subset of units to dropout\n",
    "        -  does make learning faster\n",
    "    -  Batch Normalization:\n",
    "        -  rescales the output of a particular layer with 0 mean and standard deviation of 1 for every batch of training\n",
    "        -  does make learning slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n\\n# Train the model and store the training object\\ntraining = model.fit(train_data, train_labels, validation_split=0.2, epochs=3, batch_size=10)\\n\\n# Extract the history from the training object\\nhistory = training.history\\n\\n# Plot the training loss \\nplt.plot(history['loss'])\\n# Plot the validation loss\\nplt.plot(history['val_loss'])\\n\\n# Show the figure\\nplt.show()\\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and store the training object\n",
    "training = model.fit(train_data, train_labels, validation_split=0.2, epochs=3, batch_size=10)\n",
    "\n",
    "# Extract the history from the training object\n",
    "history = training.history\n",
    "\n",
    "# Plot the training loss \n",
    "plt.plot(history['loss'])\n",
    "# Plot the validation loss\n",
    "plt.plot(history['val_loss'])\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### store model weights & predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Load the weights from file\\nmodel.load_weights('weights.hdf5')\\n\\n# Predict from the first three images in the test data\\nmodel.predict(test_data[:3])\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Load the weights from file\n",
    "model.load_weights('weights.hdf5')\n",
    "\n",
    "# Predict from the first three images in the test data\n",
    "model.predict(test_data[:3])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a dropout layer\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract kernel from trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Load the weights into the model\\nmodel.load_weights('weights.hdf5')\\n\\n# Get the first convolutional layer from the model\\nc1 = model.layers[0]\\n\\n# Get the weights of the first convolutional layer\\nweights1 = c1.get_weights()\\n\\n# Pull out the first channel of the first kernel in the first layer\\nkernel = weights1[0][...,0, 0]\\nprint(kernel)\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Load the weights into the model\n",
    "model.load_weights('weights.hdf5')\n",
    "\n",
    "# Get the first convolutional layer from the model\n",
    "c1 = model.layers[0]\n",
    "\n",
    "# Get the weights of the first convolutional layer\n",
    "weights1 = c1.get_weights()\n",
    "\n",
    "# Pull out the first channel of the first kernel in the first layer\n",
    "kernel = weights1[0][...,0, 0]\n",
    "print(kernel)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shape of weights extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2, 2, 1, 5)\n",
    "# (kernel size height, kernel size width, channel, # of weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize kernel response to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(image, kernel):\n",
    "    kernel = kernel - kernel.mean()\n",
    "    result = np.zeros(image.shape)\n",
    "    for ii in range(image.shape[0]-2):\n",
    "        for jj in range(image.shape[1]-2):\n",
    "            result[ii, jj] = np.sum(image[ii:ii+2, jj:jj+2] * kernel)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\n\\n# Convolve with the fourth image in test_data\\nout = convolution(test_data[3, :, :, 0], kernel)\\n\\n# Visualize the result\\nplt.imshow(out)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convolve with the fourth image in test_data\n",
    "out = convolution(test_data[3, :, :, 0], kernel)\n",
    "\n",
    "# Visualize the result\n",
    "plt.imshow(out)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
